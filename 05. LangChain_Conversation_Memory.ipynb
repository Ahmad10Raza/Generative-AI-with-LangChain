{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory In LangChain?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversation Memory in LangChain: Keeping Context Alive\n",
    "\n",
    "Conversation memory in LangChain plays a crucial role in creating **context-aware and engaging dialogues**. It stores relevant information from past interactions, allowing the LLM to build upon and reference previous statements within its responses. This enhances the conversational flow and makes interactions feel more natural and personalized.\n",
    "\n",
    "**Here's a deeper dive into Conversation Memory:**\n",
    "\n",
    "**Types of Memories:**\n",
    "\n",
    "- **Simple Buffer:** Stores a limited number of recent messages, enabling basic context continuity.\n",
    "- **Summary Buffer:** Combines recent interactions into a concise summary, capturing key points.\n",
    "- **World Model:** Maintains a more complex representation of the conversation, including entities, relationships, and past events.\n",
    "\n",
    "**Benefits of Using Conversation Memory:**\n",
    "\n",
    "- **Natural Conversations:** The LLM can refer back to previous statements, avoid repetition, and adapt its responses based on the conversation history.\n",
    "- **Personalized Responses:** Responses can be tailored to the user's specific interests and preferences as remembered from past interactions.\n",
    "- **Complex Tasks:** Long-term contexts enable tackling multi-step tasks or engaging in extended dialogues with consistent threads.\n",
    "\n",
    "**LangChain Components for Conversation Memory:**\n",
    "\n",
    "- **ConversationBufferMemory:** Stores a simple buffer of recent messages.\n",
    "- **ConversationSummaryBufferMemory:** Combines past interactions into a summary.\n",
    "- **MemoryChain:** Enables complex workflows involving the memory.\n",
    "\n",
    "**Example Use Cases:**\n",
    "\n",
    "- **Chatbots:** Maintain personalized conversations within customer service or virtual assistant applications.\n",
    "- **Interactive Narratives:** Track character dialogue and story state for dynamic storytelling experiences.\n",
    "- **Task Completion:** Guide the LLM through multi-step tasks by remembering previous instructions and progress.\n",
    "\n",
    "**Implementing Conversation Memory:**\n",
    "\n",
    "Choose the appropriate memory component based on your need for complexity and context depth. Integrate it into your LangChain chain to store and access information during LLM interactions.\n",
    "\n",
    "**Remember, effective conversation memory management is key to building engaging and coherent conversational applications with LangChain. Experiment with different memory types and explore their potential to enrich your projects!**\n",
    "\n",
    "Feel free to ask if you have further questions about specific memory components, use cases, or implementation details. I'm here to help you leverage the power of conversation memory in your LangChain creations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Types?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Here's a list of memory types in LangChain, along with brief descriptions:**\n",
    "\n",
    "**1. Conversation Memory:**\n",
    "\n",
    "- **ConversationBufferMemory:** Stores a limited number of recent messages for basic context continuity.\n",
    "- **ConversationSummaryBufferMemory:** Combines recent interactions into a concise summary, capturing key points.\n",
    "\n",
    "**2. External Memory:**\n",
    "\n",
    "- **DocumentStoreChain:** Interacts with document stores like Pinecone for retrieval and integration of structured data.\n",
    "- **TextIndexChain:** Connects with text indexes for full-text search and retrieval of relevant information.\n",
    "\n",
    "**3. Internal Memory:**\n",
    "\n",
    "- **MemoryChain:** Enables complex workflows involving memory, such as storing and retrieving data within chains.\n",
    "- **Custom Memory Components:** You can create custom memory components tailored to your specific needs.\n",
    "\n",
    "**4. LLM-Specific Memory:**\n",
    "\n",
    "- **LLM-Internal Memory:** Some LLMs have their own internal memory mechanisms that can be leveraged within LangChain.\n",
    "\n",
    "**Additional Considerations:**\n",
    "\n",
    "- **Hybrid Approaches:** Combine different memory types for more comprehensive context management.\n",
    "- **Persistence:** Explore options for persisting memory content across sessions for long-term continuity.\n",
    "\n",
    "**Choosing the appropriate memory types depends on your specific use case and the level of context awareness required for your application.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Converstation Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "from langchain.llms import OpenAI  # Or any other supported LLM adapter\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# Connect to an LLM\n",
    "llm = OpenAI(temperature=0.9)  # Adjust temperature as needed\n",
    "\n",
    "# Create a conversation memory with a buffer size of 10\n",
    "memory = ConversationBufferMemory(max_history_tokens=1000)\n",
    "\n",
    "# Create a chain with the LLM and memory\n",
    "chain = langchain.Chain(components=[llm, memory])\n",
    "\n",
    "# Initiate a conversation\n",
    "user_input = \"Hello, how are you?\"\n",
    "response = chain.run(user_input)\n",
    "print(response.text)\n",
    "\n",
    "# Continue the conversation, building context\n",
    "user_input = \"I'm doing well, thanks for asking. What's your favorite color?\"\n",
    "response = chain.run(user_input)\n",
    "print(response.text)  # Response will be influenced by previous messages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Explanation:**\n",
    "\n",
    "1. **Import Libraries:** Import necessary modules for LangChain, LLM adapters, and memory components.\n",
    "2. **Connect LLM:** Create an instance of the LLM adapter to interact with the LLM.\n",
    "3. **Create Memory:** Instantiate a `ConversationBufferMemory` object with a specified buffer size.\n",
    "4. **Construct Chain:** Create a LangChain with the LLM and memory as its components.\n",
    "5. **Initiate Conversation:** Send a user input to the chain, starting the interaction.\n",
    "6. **Access Memory:** The chain automatically stores messages and context in the memory.\n",
    "7. **Continue Conversation:** Subsequent user inputs build upon the stored context, influencing responses.\n",
    "\n",
    "**Key Points:**\n",
    "\n",
    "- `ConversationBufferMemory` stores a limited history of messages for basic context continuity.\n",
    "- The chain manages interactions with both the LLM and memory.\n",
    "- Experiment with different memory types and buffer sizes for optimal results.\n",
    "- Explore advanced memory workflows using `MemoryChain` and custom components.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. External Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Types of External Memory:**\n",
    "\n",
    "- **TextIndexChain:** Connects your LangChain to external text indexes like Elasticsearch or Solr. Allows full-text search and retrieval of relevant information from indexed documents.\n",
    "\n",
    "- **DocumentStoreChain:** Integrates with document stores like Pinecone or Google Cloud Storage. Enables access and manipulation of structured data like JSON documents or tables.\n",
    "\n",
    "**Benefits of External Memory:**\n",
    "\n",
    "- **Enriched Context:** Utilize data beyond user input by incorporating information from external sources.\n",
    "- **Enhanced Capabilities:** Perform tasks like question answering, document summarization, or data analysis using stored information.\n",
    "- **Real-World Integration:** Access databases, APIs, or cloud storage within your LangChain applications.\n",
    "\n",
    "**Python Code Examples:**\n",
    "\n",
    "**1. TextIndexChain:**\n",
    "\n",
    "```python\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.memory import TextIndexChain\n",
    "\n",
    "# Create a TextIndexChain with your Elasticsearch connection details\n",
    "index_chain = TextIndexChain(es_host=\"http://localhost:9200\", es_index=\"my_index\")\n",
    "\n",
    "# Build a chain with the LLM and TextIndexChain\n",
    "chain = langchain.Chain(components=[OpenAI(), index_chain])\n",
    "\n",
    "# User asks a question: \"What is the capital of France?\"\n",
    "user_input = \"What is the capital of France?\"\n",
    "\n",
    "# Chain retrieves relevant information from the text index and uses it in the response\n",
    "response = chain.run(user_input)\n",
    "print(response.text)\n",
    "```\n",
    "\n",
    "**2. DocumentStoreChain:**\n",
    "\n",
    "```python\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.memory import DocumentStoreChain\n",
    "\n",
    "# Create a DocumentStoreChain with your Pinecone connection details\n",
    "ds_chain = DocumentStoreChain(pinecone_api_key=\"YOUR_API_KEY\")\n",
    "\n",
    "# Build a chain with the LLM and DocumentStoreChain\n",
    "chain = langchain.Chain(components=[OpenAI(), ds_chain])\n",
    "\n",
    "# User asks for a product summary: \"Summarize the features of the iPhone 14\"\n",
    "user_input = \"Summarize the features of the iPhone 14\"\n",
    "\n",
    "# Chain retrieves the relevant document from the store and uses its content for the response\n",
    "response = chain.run(user_input)\n",
    "print(response.text)\n",
    "```\n",
    "\n",
    "**Remember:**\n",
    "\n",
    "- Choose the appropriate external memory type based on your data type and access needs.\n",
    "- Configure connection details and credentials for access to external sources.\n",
    "- Experiment with different data retrieval strategies and integration methods within your chains.\n",
    "\n",
    "Feel free to ask any further questions about specific external memory implementations or use cases. I'm here to guide you through expanding your LangChain applications with the power of external data!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Internal Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "**Internal Memory Components:**\n",
    "\n",
    "- **MemoryChain:** This specialized chain component enables you to create custom memory workflows within your LangChain applications. It provides functions for storing, retrieving, and manipulating data within the chain itself, allowing for more intricate memory interactions.\n",
    "\n",
    "**Key Features of MemoryChain:**\n",
    "\n",
    "- **Flexibility:** Design tailored memory structures and interactions to suit your specific needs.\n",
    "- **State Management:** Store and manage state information within the chain, enabling context-aware responses and decision-making.\n",
    "- **Complex Data Handling:** Store and process structured data, lists, or dictionaries for advanced tasks.\n",
    "\n",
    "**Python Code Example:**\n",
    "\n",
    "```python\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.memory import MemoryChain, Memory\n",
    "\n",
    "# Create a MemoryChain\n",
    "memory_chain = MemoryChain()\n",
    "\n",
    "# Add a memory component to store user preferences\n",
    "user_preferences = Memory(initial_data={\"favorite_color\": \"blue\", \"likes_cats\": True})\n",
    "memory_chain.add_component(user_preferences)\n",
    "\n",
    "# Build a chain with the LLM and MemoryChain\n",
    "chain = langchain.Chain(components=[OpenAI(), memory_chain])\n",
    "\n",
    "# User asks a question, referencing their preferences\n",
    "user_input = \"Do you think I would like a blue cat?\"\n",
    "\n",
    "# Chain accesses user preferences from memory and uses them in the response\n",
    "response = chain.run(user_input)\n",
    "print(response.text)  # Response will consider user's preferences\n",
    "```\n",
    "\n",
    "**Additional Considerations:**\n",
    "\n",
    "- **Custom Memory Components:** Create custom memory components to address specific use cases and data structures.\n",
    "- **Integration with Other Memory Types:** Combine internal memory with conversation memory or external memory for comprehensive context management.\n",
    "\n",
    "**Remember:**\n",
    "\n",
    "- Explore MemoryChain for fine-grained control over memory interactions within your chains.\n",
    "- Experiment with different memory structures and data types to meet your application's requirements.\n",
    "- Consider using custom memory components for unique needs and tailored data handling.\n",
    "\n",
    "I'm here to assist you further if you have any questions about specific use cases or implementation details. Let's unlock the potential of internal memory in LangChain together!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Custom Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Creating Custom Memory Components:**\n",
    "\n",
    "1. **Subclass `MemoryComponent`:** Inherit from the `langchain.memory.MemoryComponent` class to create a custom memory component.\n",
    "2. **Define Required Methods:** Implement these essential methods:\n",
    "   - `initial_data()`: Returns the initial data to be stored in the memory.\n",
    "   - `process_input(self, input_text)`: Processes incoming text and updates the memory accordingly.\n",
    "   - `get_output(self)`: Retrieves the current memory state for use in response generation.\n",
    "\n",
    "**Example Code:**\n",
    "\n",
    "```python\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.memory import MemoryComponent\n",
    "\n",
    "class UserPreferencesMemory(MemoryComponent):\n",
    "    def initial_data(self):\n",
    "        return {\"favorite_color\": None, \"likes_cats\": None}\n",
    "\n",
    "    def process_input(self, input_text):\n",
    "        # Parse input to extract user preferences and update memory\n",
    "        if \"favorite color\" in input_text:\n",
    "            self.data[\"favorite_color\"] = extract_favorite_color(input_text)\n",
    "        if \"cats\" in input_text:\n",
    "            self.data[\"likes_cats\"] = infer_cat_liking(input_text)\n",
    "\n",
    "    def get_output(self):\n",
    "        return self.data\n",
    "```\n",
    "\n",
    "**Integrating Custom Memory into Chains:**\n",
    "\n",
    "1. **Instantiate the Component:** Create an instance of your custom memory component.\n",
    "2. **Add It to a Chain:** Incorporate the component into your LangChain's component list.\n",
    "\n",
    "**Example Chain:**\n",
    "\n",
    "```python\n",
    "chain = langchain.Chain(components=[OpenAI(), UserPreferencesMemory()])\n",
    "```\n",
    "\n",
    "**Benefits of Custom Memory:**\n",
    "\n",
    "- **Tailored Data Structures:** Create memory structures that perfectly align with your application's needs.\n",
    "- **Unique Data Handling:** Implement logic for specific data processing and storage requirements.\n",
    "- **Enhanced Flexibility:** Address specialized use cases that aren't covered by built-in memory components.\n",
    "\n",
    "**Remember:**\n",
    "\n",
    "- Design custom memory components carefully to ensure efficient data management and integration with other chain components.\n",
    "- Thoroughly test your custom memory components to guarantee their effectiveness and reliability within your LangChain applications.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Thank You!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
