{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "435afb4b",
   "metadata": {},
   "source": [
    "#  **Integration with LangChain**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e237caab",
   "metadata": {},
   "source": [
    "### üß† Using `LCEL` (LangChain Expression Language) with LangGraph\n",
    "\n",
    "\n",
    "\n",
    "LangChain Expression Language (**LCEL**) is a declarative and composable syntax that allows you to define **chains** as **data objects** instead of imperative Python functions. When combined with **LangGraph**, LCEL enables you to define complex graph nodes in a **clean**, **composable**, and **declarative** way.\n",
    "\n",
    "\n",
    "\n",
    "## ‚úÖ Why use LCEL with LangGraph?\n",
    "\n",
    "* üì¶ **Modular Design**: Build reusable logic blocks.\n",
    "* üîó **Chain Composition**: Easily connect LLMs, tools, memory, etc.\n",
    "* üîÑ **Declarative Syntax**: Express what you want to happen without writing imperative logic.\n",
    "* ‚öôÔ∏è **Great for nodes** in LangGraph where each node is a chain of actions.\n",
    "\n",
    "\n",
    "\n",
    "## üß± LCEL Syntax Basics\n",
    "\n",
    "```python\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"Translate this to French: {text}\")\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "chain = prompt | llm\n",
    "```\n",
    "\n",
    "This uses `|` operator (pipe) to **compose** prompt and LLM into a chain.\n",
    "\n",
    "\n",
    "\n",
    "## üß† Using LCEL Chains as LangGraph Nodes\n",
    "\n",
    "```python\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# Define your LCEL-based node\n",
    "translation_node = prompt | llm\n",
    "\n",
    "# Define your graph\n",
    "builder = StateGraph(dict)\n",
    "\n",
    "builder.add_node(\"translate\", translation_node)\n",
    "builder.set_entry_point(\"translate\")\n",
    "builder.set_finish_point(\"translate\")  # No branching\n",
    "\n",
    "graph = builder.compile()\n",
    "```\n",
    "\n",
    "Now you can run it with:\n",
    "\n",
    "```python\n",
    "result = graph.invoke({\"text\": \"Good morning\"})\n",
    "print(result)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "## üß† LCEL for Tool Usage in Graphs\n",
    "\n",
    "```python\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def multiply(input):\n",
    "    return {\"result\": input[\"a\"] * input[\"b\"]}\n",
    "\n",
    "multiply_node = RunnableLambda(multiply)\n",
    "\n",
    "builder.add_node(\"multiply\", multiply_node)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "## üí° Benefits\n",
    "\n",
    "| Feature              | LCEL with LangGraph                      |\n",
    "| -------------------- | ---------------------------------------- |\n",
    "| üîå Composability     | Easily stack prompt ‚Üí LLM ‚Üí parser       |\n",
    "| üßº Clean Syntax      | Less boilerplate, more readable          |\n",
    "| üîÅ Reusability       | Reuse same chains across different nodes |\n",
    "| üõ†Ô∏è Tool Integration | Compose tools with LLMs declaratively    |\n",
    "\n",
    "\n",
    "\n",
    "## üöÄ Final Example\n",
    "\n",
    "```python\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"Summarize: {text}\")\n",
    "llm = ChatOpenAI()\n",
    "summarize_chain = prompt | llm\n",
    "\n",
    "builder = StateGraph(dict)\n",
    "builder.add_node(\"summarize\", summarize_chain)\n",
    "builder.set_entry_point(\"summarize\")\n",
    "builder.set_finish_point(\"summarize\")\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "output = graph.invoke({\"text\": \"LangGraph lets you build complex workflows with LLMs.\"})\n",
    "print(output)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1d91cd",
   "metadata": {},
   "source": [
    "# Integrating chains and tools as LangGraph nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6f361e",
   "metadata": {},
   "source": [
    "### üîó Integrating Chains and Tools as LangGraph Nodes\n",
    "\n",
    "In **LangGraph**, each **node** represents a single **step** or **action** in a workflow. These nodes can be:\n",
    "\n",
    "* A **LangChain LCEL chain**\n",
    "* A **tool** (a function or API)\n",
    "* A **custom Python function**\n",
    "* Any **Runnable** (e.g., RunnableLambda, RunnableMap)\n",
    "\n",
    "When you integrate **chains** and **tools** as LangGraph nodes, you're defining how your LLM-based system processes data at each step.\n",
    "\n",
    "\n",
    "\n",
    "## ‚úÖ Step-by-Step Guide\n",
    "\n",
    "### 1. **Import Required Modules**\n",
    "\n",
    "```python\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langgraph.graph import StateGraph, END\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### 2. **Define a Chain Node (LCEL)**\n",
    "\n",
    "```python\n",
    "prompt = PromptTemplate.from_template(\"Translate to French: {text}\")\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "translate_chain = prompt | llm\n",
    "```\n",
    "\n",
    "Here `translate_chain` is an LCEL pipeline ‚Üí can be added as a graph node.\n",
    "\n",
    "\n",
    "\n",
    "### 3. **Define a Tool Node (Python Function)**\n",
    "\n",
    "```python\n",
    "def multiply(inputs):\n",
    "    return {\"result\": inputs[\"a\"] * inputs[\"b\"]}\n",
    "\n",
    "multiply_node = RunnableLambda(multiply)\n",
    "```\n",
    "\n",
    "This converts a simple function into a node-compatible object.\n",
    "\n",
    "\n",
    "\n",
    "### 4. **Build the LangGraph**\n",
    "\n",
    "```python\n",
    "builder = StateGraph(dict)\n",
    "\n",
    "builder.add_node(\"translate\", translate_chain)\n",
    "builder.add_node(\"multiply\", multiply_node)\n",
    "\n",
    "# Add a static transition just for example\n",
    "builder.set_entry_point(\"translate\")\n",
    "builder.add_edge(\"translate\", \"multiply\")\n",
    "builder.set_finish_point(\"multiply\")\n",
    "\n",
    "graph = builder.compile()\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### 5. **Run the Graph**\n",
    "\n",
    "```python\n",
    "result = graph.invoke({\"text\": \"Good morning\", \"a\": 5, \"b\": 6})\n",
    "print(result)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "## üß† Key Concepts\n",
    "\n",
    "| Term         | Meaning                                               |           |\n",
    "| ------------ | ----------------------------------------------------- | --------- |\n",
    "| **Node**     | A function, tool, or LCEL chain that does one task    |           |\n",
    "| **Runnable** | Any composable, callable object (`RunnableLambda`, \\` | \\`, etc.) |\n",
    "| **Edge**     | Defines the flow from one node to another             |           |\n",
    "| **State**    | A dictionary passed and modified between nodes        |           |\n",
    "\n",
    "\n",
    "\n",
    "## üí° Use Case Examples\n",
    "\n",
    "| Node Type    | Example                            |\n",
    "| ------------ | ---------------------------------- |\n",
    "| Chain (LCEL) | Prompt ‚Üí LLM ‚Üí Output              |\n",
    "| Tool         | Math function, search API, DB call |\n",
    "| Combined     | Prompt ‚Üí LLM ‚Üí Tool ‚Üí Output       |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f7e230",
   "metadata": {},
   "source": [
    "#  Integrating chains and tools as LangGraph nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0261b705",
   "metadata": {},
   "source": [
    "### üîó Integrating Chains and Tools as LangGraph Nodes\n",
    "\n",
    "In **LangGraph**, each **node** represents a single **step** or **action** in a workflow. These nodes can be:\n",
    "\n",
    "* A **LangChain LCEL chain**\n",
    "* A **tool** (a function or API)\n",
    "* A **custom Python function**\n",
    "* Any **Runnable** (e.g., RunnableLambda, RunnableMap)\n",
    "\n",
    "When you integrate **chains** and **tools** as LangGraph nodes, you're defining how your LLM-based system processes data at each step.\n",
    "\n",
    "\n",
    "\n",
    "## ‚úÖ Step-by-Step Guide\n",
    "\n",
    "### 1. **Import Required Modules**\n",
    "\n",
    "```python\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langgraph.graph import StateGraph, END\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### 2. **Define a Chain Node (LCEL)**\n",
    "\n",
    "```python\n",
    "prompt = PromptTemplate.from_template(\"Translate to French: {text}\")\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "translate_chain = prompt | llm\n",
    "```\n",
    "\n",
    "Here `translate_chain` is an LCEL pipeline ‚Üí can be added as a graph node.\n",
    "\n",
    "\n",
    "\n",
    "### 3. **Define a Tool Node (Python Function)**\n",
    "\n",
    "```python\n",
    "def multiply(inputs):\n",
    "    return {\"result\": inputs[\"a\"] * inputs[\"b\"]}\n",
    "\n",
    "multiply_node = RunnableLambda(multiply)\n",
    "```\n",
    "\n",
    "This converts a simple function into a node-compatible object.\n",
    "\n",
    "\n",
    "\n",
    "### 4. **Build the LangGraph**\n",
    "\n",
    "```python\n",
    "builder = StateGraph(dict)\n",
    "\n",
    "builder.add_node(\"translate\", translate_chain)\n",
    "builder.add_node(\"multiply\", multiply_node)\n",
    "\n",
    "# Add a static transition just for example\n",
    "builder.set_entry_point(\"translate\")\n",
    "builder.add_edge(\"translate\", \"multiply\")\n",
    "builder.set_finish_point(\"multiply\")\n",
    "\n",
    "graph = builder.compile()\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### 5. **Run the Graph**\n",
    "\n",
    "```python\n",
    "result = graph.invoke({\"text\": \"Good morning\", \"a\": 5, \"b\": 6})\n",
    "print(result)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "## üß† Key Concepts\n",
    "\n",
    "| Term         | Meaning                                               |           |\n",
    "| ------------ | ----------------------------------------------------- | --------- |\n",
    "| **Node**     | A function, tool, or LCEL chain that does one task    |           |\n",
    "| **Runnable** | Any composable, callable object (`RunnableLambda`, \\` | \\`, etc.) |\n",
    "| **Edge**     | Defines the flow from one node to another             |           |\n",
    "| **State**    | A dictionary passed and modified between nodes        |           |\n",
    "\n",
    "\n",
    "\n",
    "## üí° Use Case Examples\n",
    "\n",
    "| Node Type    | Example                            |\n",
    "| ------------ | ---------------------------------- |\n",
    "| Chain (LCEL) | Prompt ‚Üí LLM ‚Üí Output              |\n",
    "| Tool         | Math function, search API, DB call |\n",
    "| Combined     | Prompt ‚Üí LLM ‚Üí Tool ‚Üí Output       |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f813b222",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
